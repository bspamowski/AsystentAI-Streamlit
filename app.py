import streamlit as st
import google.generativeai as genai
from PIL import Image
import io
import json

# --- Konfiguracja API i FAQ ---
try:
    genai.configure(api_key=st.secrets["GOOGLE_API_KEY"])
except KeyError:
    st.error("BÅ‚Ä…d konfiguracji: Klucz API Google Gemini (GOOGLE_API_KEY) nie zostaÅ‚ znaleziony w pliku .streamlit/secrets.toml. "
             "Upewnij siÄ™, Å¼e plik istnieje i zawiera poprawny klucz.")
    st.stop()
except Exception as e:
    st.error(f"WystÄ…piÅ‚ bÅ‚Ä…d podczas konfiguracji API Gemini: {e}")
    st.stop()

# Wczytaj FAQ
try:
    with open("faq.json", "r", encoding="utf-8") as f:
        FAQ_DATA = json.load(f)
except FileNotFoundError:
    st.error("BÅ‚Ä…d: Plik 'faq.json' nie zostaÅ‚ znaleziony. Upewnij siÄ™, Å¼e znajduje siÄ™ w tym samym katalogu co 'app.py'.")
    FAQ_DATA = []
except json.JSONDecodeError:
    st.error("BÅ‚Ä…d: Plik 'faq.json' jest niepoprawnie sformatowany (nie jest prawidÅ‚owym JSON-em).")
    FAQ_DATA = []

# Inicjalizacja modelu Gemini 1.5 Flash (dla obrazÃ³w i tekstu)
# Ten model jest multimodalny i moÅ¼e przyjmowaÄ‡ zarÃ³wno obrazy, jak i tekst.
# Jest to optymalne rozwiÄ…zanie dla tego projektu.
model = genai.GenerativeModel('gemini-1.5-flash')

# --- Funkcje asystenta ---

def describe_and_tag_image(image_bytes):
    """
    Opisuje zawartoÅ›Ä‡ zdjÄ™cia i generuje tagi za pomocÄ… Gemini 1.5 Flash.
    """
    image_part = {
        'mime_type': 'image/jpeg', # Dostosuj typ MIME jeÅ›li potrzebujesz (np. 'image/png')
        'data': image_bytes
    }
    
    prompt_parts = [
        "Opisz szczegÃ³Å‚owo zawartoÅ›Ä‡ tego zdjÄ™cia, koncentrujÄ…c siÄ™ na gÅ‚Ã³wnych obiektach, osobach, akcjach, kolorach i ogÃ³lnym kontekÅ›cie. NastÄ™pnie, wygeneruj listÄ™ od 5 do 10 sÅ‚Ã³w kluczowych (tagÃ³w) oddzielonych przecinkami, ktÃ³re najlepiej charakteryzujÄ… to zdjÄ™cie. Format odpowiedzi: Opis: [TwÃ³j opis]. Tagi: [tag1, tag2, ...].",
        image_part
    ]
    
    try:
        response = model.generate_content(prompt_parts)
        text_response = response.text.strip()
        
        description = "Brak opisu."
        tags = "Brak tagÃ³w."
        
        if "Opis:" in text_response and "Tagi:" in text_response:
            parts = text_response.split("Tagi:", 1)
            description = parts[0].replace("Opis:", "").strip()
            tags = parts[1].strip()
        elif "Opis:" in text_response:
            description = text_response.replace("Opis:", "").strip()
        elif "Tagi:" in text_response:
             tags = text_response.replace("Tagi:", "").strip()
        else:
            description = text_response
            if len(description.split()) > 5:
                potential_tags = [word.strip(",.") for word in description.lower().split() if len(word) > 2 and word not in ["a", "an", "the", "is", "are", "on", "in", "of", "with", "and", "or", "dla", "do", "na", "w", "z"]]
                tags = ", ".join(list(set(potential_tags[:10])))
            else:
                tags = "Brak wyraÅºnych tagÃ³w."

        return description, tags
    except Exception as e:
        st.error(f"WystÄ…piÅ‚ bÅ‚Ä…d podczas opisywania/tagowania zdjÄ™cia: {e}. SprawdÅº, czy TwÃ³j klucz API jest prawidÅ‚owy i czy nie przekroczyÅ‚eÅ› limitÃ³w usage.")
        return "Nie udaÅ‚o siÄ™ opisaÄ‡ zdjÄ™cia. SprÃ³buj ponownie.", "Brak tagÃ³w."

def answer_question(user_question, image_description=None, image_tags=None):
    """
    Odpowiada na pytanie uÅ¼ytkownika, uwzglÄ™dniajÄ…c kontekst FAQ i/lub zdjÄ™cie.
    """
    # Przygotuj kontekst FAQ
    faq_context = ""
    if FAQ_DATA:
        faq_context += "Kontekst FAQ:\n"
        for entry in FAQ_DATA:
            faq_context += f"Pytanie: {entry['pytanie']}\nOdpowiedÅº: {entry['odpowiedz']}\n---\n"
    else:
        faq_context = "Brak dostÄ™pnego kontekstu FAQ.\n"

    # Przygotuj kontekst zdjÄ™cia, jeÅ›li jest dostÄ™pny
    image_context = ""
    if image_description and image_tags:
        image_context = f"\nKontekst zdjÄ™cia:\nOpis: {image_description}\nTagi: {image_tags}\n"
    elif image_description:
        image_context = f"\nKontekst zdjÄ™cia:\nOpis: {image_description}\n"
    
    # Budowanie promptu
    prompt = f"""
    JesteÅ› asystentem, ktÃ³ry odpowiada na pytania uÅ¼ytkownika.
    Twoja odpowiedÅº powinna byÄ‡ oparta na dostarczonym kontekÅ›cie FAQ oraz/lub opisie przesÅ‚anego zdjÄ™cia.
    JeÅ›li pytanie dotyczy zdjÄ™cia, odwoÅ‚aj siÄ™ do jego opisu.
    JeÅ›li pytanie dotyczy FAQ, odwoÅ‚aj siÄ™ do kontekstu FAQ.
    JeÅ›li pytanie nie pasuje do Å¼adnego z kontekstÃ³w, odpowiedz, Å¼e nie moÅ¼esz pomÃ³c z tym pytaniem i zaproponuj kontakt z obsÅ‚ugÄ… klienta.

    {faq_context}
    {image_context}

    Pytanie uÅ¼ytkownika: {user_question}
    OdpowiedÅº:
    """
    
    try:
        # WysyÅ‚amy tylko tekstowy prompt, poniewaÅ¼ obraz zostaÅ‚ juÅ¼ przetworzony na opis.
        # JeÅ›li chcielibyÅ›my, Å¼eby LLM "widziaÅ‚" obraz przy kaÅ¼dym pytaniu,
        # musielibyÅ›my przekazywaÄ‡ go w kaÅ¼dym zapytaniu, co zwiÄ™kszyÅ‚oby koszty/opÃ³Åºnienia.
        # Dla tego scenariusza, opis tekstowy jest wystarczajÄ…cym kontekstem.
        response = model.generate_content(prompt)
        return response.text.strip()
    except Exception as e:
        st.error(f"WystÄ…piÅ‚ bÅ‚Ä…d podczas odpowiadania na pytanie: {e}. SprÃ³buj zadaÄ‡ pytanie ponownie.")
        return "Nie udaÅ‚o siÄ™ udzieliÄ‡ odpowiedzi na pytanie z powodu bÅ‚Ä™du."

# --- Interfejs Streamlit ---

st.set_page_config(page_title="Asystent AI: Opis i FAQ", layout="centered")
st.title("ğŸ¤– Asystent AI: Opis ZdjÄ™Ä‡ i FAQ (wersja multimodalna)")
st.markdown("Witaj! Jestem asystentem, ktÃ³ry potrafi opisaÄ‡ i otagowaÄ‡ przesÅ‚ane zdjÄ™cia, a takÅ¼e odpowiedzieÄ‡ na pytania dotyczÄ…ce naszego FAQ lub przesÅ‚anego obrazu.")

# Zmienne stanu sesji do przechowywania opisu i tagÃ³w zdjÄ™cia
if 'image_description' not in st.session_state:
    st.session_state['image_description'] = None
if 'image_tags' not in st.session_state:
    st.session_state['image_tags'] = None
if 'uploaded_image_bytes' not in st.session_state:
    st.session_state['uploaded_image_bytes'] = None


# Sekcja opisywania zdjÄ™Ä‡
st.header("ğŸ“¸ PrzeÅ›lij i Otaguj ZdjÄ™cie")
uploaded_file = st.file_uploader("Wybierz zdjÄ™cie (JPG, PNG) do analizy:", type=["jpg", "jpeg", "png"])

if uploaded_file is not None:
    # Tylko jeÅ›li przesÅ‚ano nowy plik, przetwarzaj go
    if st.session_state['uploaded_image_bytes'] != uploaded_file.getvalue():
        st.session_state['uploaded_image_bytes'] = uploaded_file.getvalue()
        
        st.image(uploaded_file, caption='PrzesÅ‚ane zdjÄ™cie', use_column_width=True)
        image_bytes = uploaded_file.getvalue()
        
        with st.spinner("AnalizujÄ™ zdjÄ™cie za pomocÄ… Gemini AI..."):
            description, tags = describe_and_tag_image(image_bytes)
            st.session_state['image_description'] = description
            st.session_state['image_tags'] = tags
            st.subheader("Opis zdjÄ™cia:")
            st.write(st.session_state['image_description'])
            st.subheader("SÅ‚owa kluczowe (tagi):")
            st.code(st.session_state['image_tags'])
    else: # JeÅ›li plik juÅ¼ byÅ‚ przesÅ‚any, po prostu go wyÅ›wietl
        st.image(uploaded_file, caption='PrzesÅ‚ane zdjÄ™cie', use_column_width=True)
        st.subheader("Opis zdjÄ™cia:")
        st.write(st.session_state['image_description'])
        st.subheader("SÅ‚owa kluczowe (tagi):")
        st.code(st.session_state['image_tags'])

# Sekcja zadawania pytaÅ„
st.header("â“ Zadaj Pytanie")
st.markdown("Zadaj pytanie dotyczÄ…ce **FAQ** lub **przesÅ‚anego zdjÄ™cia** (jeÅ›li zostaÅ‚o przeanalizowane).")
user_question = st.text_input("Wpisz swoje pytanie tutaj:", key="general_question_input")

if user_question:
    if st.button("Zadaj pytanie"):
        with st.spinner("Szukam odpowiedzi..."):
            answer = answer_question(
                user_question,
                image_description=st.session_state['image_description'],
                image_tags=st.session_state['image_tags']
            )
            st.subheader("OdpowiedÅº:")
            st.info(answer)

st.markdown("---")
